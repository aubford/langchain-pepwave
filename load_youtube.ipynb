{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from langchain_community.document_loaders.youtube import YoutubeLoader\n",
    "from VideoItem import VideoItem\n",
    "\n",
    "load_dotenv()  # take environment variables from .env\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"USER_AGENT\"] = os.getenv(\"USER_AGENT\")\n",
    "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_channel_id(api_key, username):\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Search for the channel by username\n",
    "    request = youtube.search().list(\n",
    "        part='snippet',\n",
    "        q=username,\n",
    "        type='channel',\n",
    "        maxResults=1\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Extract the channel ID from the response\n",
    "    if response['items']:\n",
    "        channel_id = response['items'][0]['snippet']['channelId']\n",
    "        return channel_id\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "channel_id = get_channel_id(YOUTUBE_API_KEY, \"@peplink\")\n",
    "print(channel_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_videos_with_transcripts(api_key, channel_id) -> List[VideoItem]:\n",
    "    youtube_client = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "    output = []\n",
    "\n",
    "    # Get uploads playlist ID for the channel\n",
    "    request = youtube_client.channels().list(part=\"contentDetails\", id=channel_id)\n",
    "    response = request.execute()\n",
    "    uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "\n",
    "    # Fetch all video IDs from the uploads playlist\n",
    "    next_page_token = None\n",
    "    while True:\n",
    "        playlist_request = youtube_client.playlistItems().list(\n",
    "            part=\"contentDetails\",\n",
    "            playlistId=uploads_playlist_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token,\n",
    "        )\n",
    "        playlist_response = playlist_request.execute()\n",
    "        for item in playlist_response[\"items\"]:\n",
    "            video_id = item[\"contentDetails\"][\"videoId\"]\n",
    "\n",
    "            # Check video privacy and caption status\n",
    "            video_request = youtube_client.videos().list(\n",
    "                part=\"status,contentDetails,snippet,statistics,topicDetails,localizations,player,recordingDetails\",\n",
    "                id=video_id\n",
    "            )\n",
    "            video_response = video_request.execute()\n",
    "            if video_response[\"items\"]:\n",
    "                video_item = video_response[\"items\"][0]\n",
    "                is_public = video_item[\"status\"][\"privacyStatus\"] == \"public\"\n",
    "\n",
    "                if is_public:\n",
    "                    try:\n",
    "                        loader = YoutubeLoader(video_id=video_id)\n",
    "                        docs = loader.load()\n",
    "                        # Add transcript content to video item\n",
    "                        video_item[\"transcript\"] = docs[0].page_content\n",
    "\n",
    "                        video = VideoItem.model_validate(video_item)\n",
    "                        output.append(video)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not load transcript for video {video_id}\")\n",
    "                        continue\n",
    "\n",
    "\n",
    "        next_page_token = playlist_response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "    return output\n",
    "\n",
    "\n",
    "videos_with_transcripts = fetch_videos_with_transcripts(YOUTUBE_API_KEY, channel_id)\n",
    "dicts = [video.model_dump() for video in videos_with_transcripts]\n",
    "\n",
    "# Write videos to JSON file\n",
    "with open(\"youtube_videos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dicts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Write videos to parquet file\n",
    "df = pd.DataFrame(dicts)\n",
    "df.to_parquet(\"youtube_videos.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
