{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdb987bc90fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "def get_tokens(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and token.isalnum()]\n",
    "    return tokens\n",
    "\n",
    "def compute_precision_from_jaccard(jaccard_similarity: float, len_a: int, len_b: int) -> float:\n",
    "    shorter_string_len = min(len_a, len_b)\n",
    "    intersection = jaccard_similarity * (len_a + len_b) / (1 + jaccard_similarity)\n",
    "    return intersection / shorter_string_len\n",
    "\n",
    "\n",
    "def compute_recall_from_jaccard(jaccard_similarity: float, len_a: int, len_b: int) -> float:\n",
    "    longer_string_len = max(len_a, len_b)\n",
    "    intersection = jaccard_similarity * (len_a + len_b) / (1 + jaccard_similarity)\n",
    "    return intersection / longer_string_len\n",
    "\n",
    "\n",
    "def cosine_similarity(a: str, b: str) -> float:\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform([a, b])\n",
    "    cosine_sim = cosine_similarity(tfidf[0], tfidf[1])\n",
    "    print(f\"Cosine Similarity: {cosine_sim[0][0]:.4f}\")\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "texts = [\n",
    "    \"This is the first text about natural language processing.\",\n",
    "    \"This is the second text. It also discusses natural language processing.\",\n",
    "    \"Natural language processing is a field of computer science.\",\n",
    "    \"This is the first text about natural language processing and stufffff.\"  # Duplicate\n",
    "]\n",
    "\n",
    "def minhash_duplicate_candidates(corpus: List[str]) -> float:\n",
    "    lsh = MinHashLSH(threshold=0.8, num_perm=128)\n",
    "    minhashes = {}\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = preprocess_text(text)\n",
    "        m = MinHash(num_perm=128)\n",
    "        for token in tokens:\n",
    "            m.update(token.encode('utf8'))\n",
    "        lsh.insert(i, m)\n",
    "        minhashes[i] = m\n",
    "\n",
    "    # Find potential duplicates\n",
    "    potential_duplicates = []\n",
    "    for i in range(len(texts)):\n",
    "        result = lsh.query(minhashes[i])\n",
    "        if len(result) > 1:\n",
    "            potential_duplicates.append((i, result))\n",
    "\n",
    "minhash_duplicate_candidates()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
