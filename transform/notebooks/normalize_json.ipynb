{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-13T02:10:03.645873Z",
     "start_time": "2024-12-13T02:10:03.623260Z"
    }
   },
   "source": [
    "from sys import displayhook\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ITEM = 'youtube'\n",
    "\n",
    "parquet_path = Path().resolve() / DATA_ITEM / 'parquet'\n",
    "raw_path = Path().resolve() / DATA_ITEM / 'raw'\n",
    "\n",
    "# get the latest parquet file\n",
    "parquet_files = list(parquet_path.glob('*.parquet'))\n",
    "latest_parquet_file = max(parquet_files, key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "# read the latest parquet file\n",
    "df = pd.read_parquet(latest_parquet_file)\n",
    "\n",
    "# count the number of rows\n",
    "print(f\"Number of rows: {len(df)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 220\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffda9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARQUET SCHEMA\n",
    "from fastparquet import ParquetFile\n",
    "pf = ParquetFile(latest_parquet_file)\n",
    "print(pf.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7430e0a306acccbb",
   "metadata": {},
   "source": [
    "\n",
    "# Convert JSON string columns to dictionaries, handling None values\n",
    "json_columns = [\n",
    "    \"snippet\",\n",
    "    \"contentDetails\",\n",
    "    \"status\",\n",
    "    \"statistics\",\n",
    "    \"player\",\n",
    "    \"topicDetails\"\n",
    "]\n",
    "\n",
    "for col in json_columns:\n",
    "    df[col] = df[col].apply(lambda x: json.loads(x) if pd.notna(x) else {})\n",
    "    \n",
    "dict_df_obj = df.to_dict('records')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T02:10:32.923904Z",
     "start_time": "2024-12-13T02:10:32.908273Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened columns: ['id', 'kind', 'etag', 'transcript', 'snippet_publishedAt', 'snippet_channelId', 'snippet_title', 'snippet_description', 'snippet_channelTitle', 'snippet_categoryId', 'snippet_liveBroadcastContent', 'contentDetails_duration', 'contentDetails_dimension', 'contentDetails_definition', 'contentDetails_caption', 'contentDetails_licensedContent', 'contentDetails_projection', 'status_uploadStatus', 'status_privacyStatus', 'status_license', 'status_embeddable', 'status_publicStatsViewable', 'status_madeForKids', 'statistics_viewCount', 'statistics_likeCount', 'statistics_favoriteCount', 'statistics_commentCount', 'player_embedHtml', 'topicDetails_topicCategories']\n"
     ]
    }
   ],
   "execution_count": 15,
   "source": [
    "\n",
    "# Now normalize the nested structures\n",
    "json_normalized_df = pd.json_normalize(\n",
    "    df.to_dict('records'),\n",
    "    sep='_',\n",
    "    max_level=None\n",
    ")\n",
    "\n",
    "# Preview the flattened columns\n",
    "print(\"Flattened columns:\", json_normalized_df.columns.tolist())\n"
   ],
   "id": "2bcf9ba7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
